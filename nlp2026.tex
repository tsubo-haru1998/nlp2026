%#!platex
% NLP2026 サンプル文書．パブリックドメイン．
\documentclass[
  platex, dvipdfmx,  % ワークフローは必ず明示的に指定する
]{nlp2026}
%english option
%\documentclass[platex, dvipdfmx, english]{nlp2026}
%#!uplatex
%\documentclass[uplatex,dvipdfmx]{nlp2026}
%#!lualatex
%\documentclass[lualatex]{nlp2026}


% パッケージ
\usepackage{graphicx,xcolor}  % グラフィックス関連
\usepackage{pxrubrica}        % ルビ
\usepackage{url}

% 以下は(u)pLaTeX用．LuaLaTeX使用時には削除すること
\usepackage[T1]{fontenc}      % モダンなフォントエンコーディング
\usepackage{jlreq-deluxe}     % 多書体化（otf パッケージは使用しない）
\usepackage{pxrubrica}        % ルビ

%% option 不要な場合はコメントアウト
\usepackage{bxjalipsum}       % ダミーテキスト
\usepackage{hyperref}
\hypersetup{
	colorlinks=true, 
    citecolor=blue, 
    linkcolor=blue,
    urlcolor=blue,
	pdfborder={0 0 0},
}
\usepackage[verb]{bxghost}    % \verb 前後に適切な和欧文間スペース

% 参考文献のフォントサイズを指定
%\renewcommand{\bibfont}{\normalsize} % 標準サイズ
%\renewcommand{\bibfont}{\footnotesize} % より小さく

% \emph をゴシックかつ太字に（比較的新しい LaTeX が必要）
\DeclareEmphSequence{\gtfamily\sffamily\bfseries}

% 著者用マクロをここに入れる
\newcommand{\pkg}[1]{\textsf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\comment}[1]{\textcolor{red}{#1}}
%%%%%%%


\title{文脈を考慮した漫画の内容理解アーキテクチャの提案}

\author{%
  坪内温暉${}^{1}$　鶴岡慶雅${}^{1}$\\
${}^{1}$東京大学
　\\ \texttt{\{tsubouchi,tsuruoka\}@logos.t.u-tokyo.ac.jp}}

\begin{document}

\maketitle
\begin{abstract}
漫画は画像とテキストが統合されたマルチモーダルの媒体である．
その物語を理解するためにはコマ間の文脈的な関係性を捉えることが不可欠である．
本研究では，動画像認識における空間・時間情報の分離処理に着想を得て，コマ内の要素間の関係とコマ間の文脈遷移を階層的に学習する漫画エンコーダのアーキテクチャを提案する．
具体的には，ComicBERTの入力表現を拡張し，Spatial EncoderとTemporal Encoderの2つのモジュールを直列に配置することで，計算の効率化と文脈理解能力の向上を図る．
次パネル予測タスクにおける評価実験の結果，提案手法は従来手法を上回る性能を示した．

\end{abstract}


\section{はじめに}
漫画は，視覚情報である画像と言語情報であるテキストが統合されたマルチモーダルな媒体である．
その物語はコマ割りや吹き出しによるセリフ表現，オノマトペ，効果線など漫画特有の技法によって読者に伝えられる．

こうした特異性から，近年では漫画の解析や理解そのものを対象とした研究が，独立した分野として進められている．
具体的には，コマ，キャラクター，文字といった漫画の構成要素を検出するモデル \cite{magiv3}やテキストに対するOCRを行うモデル，あるいは特定のコマやページに関する質問に回答するモデル \cite{mangaVQAandLMM}などが提案されている．
しかし，既存の多くのモデルは解析や理解を行う対象が単一のコマ，あるいはページに限定されている．
物語の流れを理解するためには，個々のコマやその構成要素の解析にとどまらず，コマ同士の文脈的な関係性も捉えるモデルを構築し，多数のコマにまたがる大域的な関係性を学習させることが必要不可欠である．

本研究では，漫画の物語の流れをより豊かに理解し，下流タスクに応用可能な漫画理解エンコーダを提案することを目的とする．
具体的には，動画像認識の分野で用いられる手法に着想を得て，動画像認識モデルが空間方向の情報と時間方向の情報を分けて処理するという考え方を漫画理解に応用する．
すなわち，コマ内の構成要素の関係性とコマ同士の文脈的な関連性の学習プロセスを分離したアーキテクチャを，ComicBERT \cite{ComicBERT}の手法を拡張することで構築する．
提案するモデルの有効性を検証するため，次パネル予測というタスクを用いた評価実験を行った．
実験の結果，提案手法が従来手法に比べ高い正答率を示した．
このことは，動画像認識で用いられるような空間情報と時間軸情報の分離が，漫画の文脈理解にも応用可能であることを示唆する．

\section{関連研究}
\label{sec:relevant_research}

\subsection{ComicBERT}
漫画に含まれるマルチモーダルな情報を統合的に扱い，構成要素同士の関係性を複数コマにわたって学習するフレームワークとして，ComicBERT \cite{ComicBERT}が提案されている．
ComicBERTでは，漫画を構成する要素としてコマ画像，キャラクター画像，吹き出し内のセリフ，ナレーションテキストの4つの異なるモダリティを定義している．
各コマに対してこれらの要素を検出し，各モダリティについてその特徴量を抽出したのち，線形射影によって共通の埋め込み空間に写像することで異なるモダリティを統一的に扱うことができる．
検出や特徴量の取得には，事前学習済みモデルが用いられている．
得られた各モダリティの埋め込みは，コマ内の構成要素を表すトークン列としてまとめられる．
それらをコマの読順に並び替えることで，Transformer \cite{Transformer}エンコーダの入力として与えられる．
この際，異なるコマを区別するため[SEP]トークンが挿入され，コマの境界が明示的に付与される．

モデルの事前学習には，masked Comic Modeling (MCM) という自己教師あり学習タスクが用いられている．
MCMではモデルの入力として与えられるモダリティ特徴量の一部がマスクされ，周囲の情報からそれらを復元する．

このようにして学習されたモデルは，各構成要素同士の関係性を，複数コマに渡って学習され，クローズ形式のタスクをはじめとした複数の下流タスクで高い性能を示している．
一方で，ComicBERTは一つのコマ内の要素同士の関係性と異なるコマの要素同士の関係性が単一のTransformerエンコーダ内で並列に処理される．
この構造により，コマ内の要素の関係性とコマ間の関係性という性質の異なる2つの情報をモデルが十分に内包できていない可能性がある．
これに対し本研究では，モダリティ定義や学習タスクは引き継ぎつつ，コマ内の要素間の関係性とコマ間の時間的・文脈的関係性を明示的に分離して処理するアーキテクチャを導入し，モデルがより適切にコマ間の関係性を理解することを目指す．

\subsection{動画像エンコーダ}
漫画はコマ画像がページ内に複数配置されるという特性をもっており，この構造はフレーム画像が時間軸方向に複数連なった動画の構造に類似している．
そのため，動画像処理のアプローチが漫画にも応用できると考えられる．

動画像処理の分野では，時間軸方向にも情報をもつ動画データを効率的に処理するかが活発に研究されている．
従来の3次元畳み込みニューラルネットワーク \cite{3DCNN}に代わり，近年ではTransformerを動画像向けに拡張したモデルが数多く提案されている．

ViViT \cite{ViViT}は，動画から抽出した時空間トークンをTransformerで処理するアーキテクチャである．
特に，空間方向のエンコーダと時間方向のエンコーダを分離するFactorized Encoderという構成を用いることで，Attention計算の負荷を軽減している．
この設計は，各フレーム内の空間的特徴を抽出したのち，フレーム間の時間的関係を捉えるという処理フローを実現しており，計算速度と精度を両立させている．
その他にも計算効率向上を目的として，時間方向のAttentionと空間方向のAttentionを交互に適用し学習を行うTimeSformer \cite{TimeSformer}や，局所的なウィンドウ単位でのAttention計算を行うVideo Swin Transformer \cite{VideoSwinTransformer}など，Attention計算に注目したモデルも提案されている．% この行はなくても

本研究では，このような既存の動画像エンコーダの構造的利点に着目し，コマ内の特徴量の抽出とコマ間の関係性の学習を分離するアプローチを漫画理解エンコーダに導入する．

\section{提案手法}
\label{sec:proposed_method}

\subsection{階層構造のエンコーダ}
ViViTのFactorized Encoderにならい，漫画のエンコーディングにおいても図\ref{fig:proposed_architecture}のような階層的なエンコーダモデルを提案する．
%アーキテクチャ図
\begin{figure}[t]
\centering
\includegraphics[width=8cm]{fig/proposed_method.pdf}
\caption{提案する階層的漫画エンコーダモデルの全体図}
\label{fig:proposed_architecture}
\end{figure}
% アーキテクチャ図終了
入力データは，$T$個のコマからなる漫画のシーケンスである．
各コマの埋め込み表現は$L$個のトークンで構成される．
アーキテクチャはSpatial EncoderとTemporal Encoderの2種類のモジュールからなり，まず各コマのトークン列を並列にSpatial Encoderに入力する．
続いて，その出力テンソルを転置することで処理の主軸をコマ内からコマ間へと切り替え，Temporal Encoderに入力し，最終的な特徴量を得る．

このようにコマ内の関係性計算とコマ間の関係性計算を明示的に分割することで，計算効率を向上させながら，より豊かな複数コマ間の文脈情報をモデルが保持することができると考えられる．

\subsection{コマの埋め込み表現}
本節では，漫画の1つのコマ画像を$L$個のトークン列に変換する手法について述べる．
図\ref{fig:input_sequences}に，ComicBERTおよび提案手法における入力シーケンスの構成を示す．
\begin{figure}[t]
\centering
\includegraphics[width=8cm]{fig/input_sequences.pdf}
\caption{各手法でのコマの埋め込み表現}
\label{fig:input_sequences}
\end{figure}

ComicBERTでは，漫画の構成要素として，以下の4つをトークンとして利用する．
\begin{itemize}
    \item \textbf{PNL (Panel)}: コマ全体の画像特徴．
    \item \textbf{CHR (Character)}: キャラクターの画像特徴．
    \item \textbf{SPC (Speech)}: CHRトークンに埋め込まれたキャラクターの吹き出し内のセリフテキストの特徴．言語エンコーダにより埋め込まれる．
    \item \textbf{NRT (Narration)}: ナレーションテキストの特徴．言語エンコーダにより埋め込まれる．
\end{itemize}
これらの特徴量は，既存のエンコーダモデルにより抽出され，線形層を通して共通の埋め込み次元$D$に射影される．

図\ref{fig:input_sequences}上段に示すように，ComicBERTではPNLトークンを1つ，CHRトークンとSPCトークンのペアを最大3組(コマ内に3キャラクター以上存在しない場合やキャラクターにセリフがない場合は該当トークンはパディングされる)，NRTトークンを1つ並べコマの埋め込み表現としている．
隣接するコマ同士は[SEP]トークンを挟んでトークン列を結合することにより区別している．
一方，提案手法（Ours）では，1つのコマの埋め込み表現はComicBERTと同じであるが，隣接するコマ同士は入力データの構造によって区別する．
ComicBERTの入力テンソルの形状は$(L, D)$と表せるが，提案手法ではモデルのアーキテクチャに合わせて新たに軸を追加してコマの埋め込み表現を並べるため，$(T, L, D)$となる．
また，全てのコマを通してCHRトークンとして登場するキャラクターの順番を固定し配置する方法（Character Ordered）も導入する．
このとき，例えば$T$コマのシーケンス内である特定のキャラクターAは各コマのトークン列内の同じ位置に登場するため，入力データがより構造化され，モデルの理解がより促進されることが期待される．

また，物体検出や埋め込み層のモジュールに依存しない別のアプローチとして，図\ref{fig:input_sequences}下段に示すパッチベース表現（Patch）も検討する．
これは，$T$コマの画像シーケンスを$T$フレームからなる動画とみなし，従来のVideo Transformerのように処理する手法である．
本研究では，これらの入力表現それぞれについて学習を行い，下流タスクで評価を行い，その性能を比較検討する．

\section{実験}

\subsection{実験設定}
データセットには，Manga109データセットおよびそのアノテーションデータ \cite{Manga109_Aizawa,Manga109_Matsui,Manga109Dialog}を用いた．
MCMによる学習および下流タスクの学習，評価については，訓練・検証・テストデータの割合を$8:1:1$とし，全てのタスクについてこの分割方法は同一とした．
これによって，下流タスクのテスト時にモデルが学習済みのコマのデータが出てこないようにした．

コマの構成要素の埋め込みについては，ComicBERTで用いられていたモデルと同様のものを使用した．
具体的には，コマの全体画像の埋め込みにはEfficientNet\cite{EfficientNet}, キャラクター画像の埋め込みにはCharacter ReID model\cite{CharReID}, セリフとナレーションの埋め込みにはSentence Transformer\cite{SentenceTransformer}のDistilRoBERTa\cite{Distilbert}を使用した．

MCMの学習時は，BERT\cite{bert}のMasked Language Modelにならい，パディングではない入力トークンのうちの20\%をマスク対象とし，マスク対象となったトークンのうちの80\%を[MASK]トークンに，10\%を別のランダムなトークンに，10\%をそのままのトークンに変えてモデルに入力した．
損失は，マスク対象のトークンに限定した最小二乗誤差とした．
% 詳細なハイパーパラメータは...

\subsection{評価タスク}
本実験では，モデルが漫画の物語の文脈を適切に理解できているかを確認する評価タスクとして次パネル予測を使用する．
これはMangaUB\cite{MangaUB}におけるnext panel inferenceやComicBERTにおけるScene-Clozeのようなタスクであり，コマのシーケンスが与えられたときに，その次のコマが何かを選択肢の中から選ぶというものである．
学習，推論時は各選択肢のコマについてその埋め込み表現を取得し，それまでのコマのシーケンスから得た埋め込み表現と結合させ，モデルに入力する．
その後モデルの出力に対しMean Poolingを施し，線形層を通して各選択肢につき1つのlogitを得る．
logitが最も高い選択肢をモデルの解答とし，その正答率をモデルの性能評価に用いた．
難易度はeasyとdifficultの2種類を設定した．
easyは選択肢のうち不正解のコマを正解のコマとは異なる本の中から抽出しており，difficultは不正解のコマを正解のコマと同じ本から抽出している．
difficultはeasyに比べ選択肢のコマの画風が似る傾向にあるため，より文脈そのものの理解が要求される．

MCMタスクで学習を行なったモデルに対し，次パネル予測タスクの学習を行い，最終的にテストデータによる正答率の評価を行なった．
学習の際，easyとdifficultの比は$2:8$とした．

\subsection{結果}
ComicBERTおよび提案手法における次パネル予測の正答率を表\ref{tab:result_acc}に示す．
\begin{table}[t]
\centering
\caption{各手法での次パネル予測正答率 [\%]}
\label{tab:result_acc}
\begin{tabular}{lcc}
\hline
 & easy & difficult\\
\hline
ComicBERT & 72.06 & 64.88\\
Ours & \textbf{74.22} & \textbf{66.98}\\
Ours (character ordered) & 69.83 & 65.35\\
Ours (patch) & 61.74 & 61.20\\
\hline
\end{tabular}
\end{table}
easy, difficultどちらの難易度においても，提案手法 (Ours) の正答率が従来手法であるComicBERTの正答率よりも高くなった．
トークン列におけるキャラクター順を固定した手法 (character ordered) や，漫画のコマ画像の連続を動画のように扱う手法 (patch) については，どちらも提案手法 (Ours) と比較して正答率が低下した．

\subsection{考察}
本研究で提案した階層型アーキテクチャ (Ours) の高い正答率は，モデルがコマ間の時間的・文脈的関係性をコマ内の要素間の関係性と分離することによって複数コマにわたる漫画の文脈をより適切に捉えられたことに起因すると考えられる．
特に難易度がdifficultのタスクでも高い正答率を示したことは，画風やキャラクターの外見的な特徴だけでなく，漫画の物語そのものを理解する能力が向上したことを示している．
このように，提案した漫画エンコーダのアーキテクチャは，その構造的利点により，計算量の削減，文脈理解精度の向上の両方を達成したといえる．

一方で，トークン列内のキャラクター順を固定した手法 (character ordered) では，順序を固定しない手法よりも正答率が低下する結果となった．
これは，入力トークン列の冗長化が主な要因であると考えられる．
Character Orderedでは，各コマでキャラクターの登場したかに関わらず，シーケンス内の全登場キャラクター分のトークンスロットを確保して配置を行うため，登場人物の少ないコマであってもトークン列が長大化し，結果として入力情報が疎になる傾向がある．
本実験の結果は，順序を固定することによる入力テンソルの構造化という利点よりも，系列長の増大に伴う学習の非効率性や情報の希薄化といった欠点の影響が大きいことを示唆している．

また，漫画のコマ画像をパッチ分割して入力する手法 (patch) での正答率も低くなった．
パッチベースの手法では，画像のみの情報からキャラクターやテキストなどの漫画特有のモダリティの意味や関係性を学習する必要があるが，本実験で用いたモデルの規模ではそれらが十分に学習されなかったと推察される．

\section{おわりに}
本研究では，コマ内の関係性とコマ間の関係性を分離して処理する漫画エンコーダのアーキテクチャを提案し，次パネル予測タスクにおいてその構造的な利点を示した．
今後の課題として，複数の下流タスクにおいてその性能を検証し，モデルの汎用性を検証することや，漫画特有のオノマトペなどのモダリティも統合的に処理可能にすることなどが挙げられる．



%%%%  ここまでが本文　4ページ以内
\newpage

% 参考文献
\bibliographystyle{junsrt}
\bibliography{cite} % ファイル名は適宜自分のbibファイルに置き換える

%%%%  ここまでが本文+参考文献　5ページ以内


% 付録(Appendix)
% 付録を付けない場合は，以下\end{document}以外を全てをコメントアウトする．
% 本文，参考文献に続けて作成する場合は，必ず \clearpage して新たなページとする

\end{document}
